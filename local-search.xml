<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>KDE桌面美化指南 Part 2</title>
    <link href="/2021/02/20/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97-2/"/>
    <url>/2021/02/20/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97-2/</url>
    
    <content type="html"><![CDATA[<p>距离上次写美化过了好久，又回到了Manjaro（就折腾呗😂）。<br />当前KDE已经更新到了5.20，自带的性能监控小插件功能更全也更好看了还多了一些新的插件修复了一些bug然后产生了新的bug，是时候更新下一篇了。</p><p><img src="2021-02-20T225737.png" alt="2021-02-20T225737" /></p><h2 id="顶栏更新"><a class="markdownIt-Anchor" href="#顶栏更新"></a> 顶栏更新</h2><p>首先是顶栏更新了一下，效果如下。</p><p><img src="2021-02-20T231002.png" alt="2021-02-20T231002" /></p><p>和之前主要的不同仅在于性能监控使用了KDE更新到5.20后自带的性能监控Widgets，想要监控什么性能指标自己加就行，啥都有，很全很KDE。自行设置了一下样式，怎么配置应该试试就会了吧～（大概）<br />另外Weather Widgets的一个天气数据来源<code>yr.no</code>由于站点更新，当前插件已经不支持了，改用<code>OWM</code>吧。</p><h2 id="字体调整"><a class="markdownIt-Anchor" href="#字体调整"></a> 字体调整</h2><p>Linux下字体渲染要比Windows下号很多，所以字号即使比较小看起来效果也比Windows下的大字要舒服些（个人觉得吧），中文字体推荐使用Noto Sans SC，不同的系统下命名可能不同，比如Manjaro下就叫Noto Sans CJK SC。字号稍微调大一些，同时把字体渲染拉满就行，凭个人感觉来。</p><p><img src="2021-02-20T232309.png" alt="2021-02-20T232309" /></p><p>如果你装系统的时候选的是英文的话（事实上推荐这么做），这个中文字体很可能是缺失的，安装好语言的支持包即可，只要不去改变系统语言就行。或者单独安装Noto Sans字体。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_">~$ </span><span class="language-bash">sudo pacman -Ss noto-fonts</span><br>extra/noto-fonts 20201226-1 [installed]<br>    Google Noto TTF fonts<br>extra/noto-fonts-cjk 20201206-1 [installed]<br>    Google Noto CJK fonts<br>extra/noto-fonts-emoji 20200916-1 [installed]<br>    Google Noto emoji fonts<br>extra/noto-fonts-extra 20201226-1<br>    Google Noto TTF fonts - additional variants<br>community/noto-fonts-compat 20151217-1 [installed]<br>    Google Noto TTF fonts (compat-package)<br></code></pre></div></td></tr></table></figure><p>至于某些应用中，比如Chrome中的字体，在应用自身的设置中是可以调整的，可以独立配置。</p><h2 id="shell相关的配置工作"><a class="markdownIt-Anchor" href="#shell相关的配置工作"></a> Shell相关的配置工作</h2><p>用Linux怎么会少的了用Shell呢。个人来讲更多是通过下拉式的Shell，比如yakuake，对应Gnome下一般就是Guake。毕竟开个Konsole还要多一个窗口，窗口一多就乱了…</p><h3 id="yakuake主题"><a class="markdownIt-Anchor" href="#yakuake主题"></a> Yakuake主题</h3><p>yysy，yakuake就没找到好看的主题QwQ。所以最后是魔改了<code>transparent-tabs</code>这一个主题，一路用到现在，反正只要够简洁就行了，效果如下。</p><p><img src="2021-02-20T234156.png" alt="2021-02-20T234156" /></p><p>直接把主题中的白边删了，弄成了简单的一条透明的标签栏。<a href="https://drive.google.com/file/d/1qsMTPaod6x1N6C0_agJh9LKn0BDIJ6dh/view?usp=sharing">下载连接在此</a>。解压后将主题文件夹放到<code>~/.local/share/yakuake/kns_skins/</code>即可，文件夹没有则自行创建。</p><p>Warning: 使用这个主题后，你会发现Yakuake的设置没地方打开了！使用快捷键<code>Ctrl+Shift+,</code>可以打开设置。</p><h3 id="yakuake终端颜色主题"><a class="markdownIt-Anchor" href="#yakuake终端颜色主题"></a> Yakuake终端颜色主题</h3><p>除了Yakuake的边框外观，还有Shell的颜色配置需要设置，不然是没有上面的透明度的。直接在Yakuake终端的空白处<code>右键&gt;Edit Current Profile...&gt;Appearance</code>配置颜色主题，选择一个黑色主题即可，并点<code>Edit</code>拉低其中的透明度即可。</p><p><img src="2021-02-21T002141.png" alt="2021-02-21T002141" /></p><h3 id="zsh主题和插件"><a class="markdownIt-Anchor" href="#zsh主题和插件"></a> ZSH主题和插件</h3><p>ZSH不必多说吧，反正对于我来说已经习惯成自然了，必须装一个。</p><p>安装了ZSH之后首先装一下Oh My Zsh，安装方法见<a href="https://ohmyz.sh/#install">官网</a>或者这边：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;<br></code></pre></div></td></tr></table></figure><p>安装后会发现<code>.zshrc</code>更新了。接下来安装下ZSH的主题，配置一下常用的插件即可。主题推荐使用<a href="https://github.com/romkatv/powerlevel10k">powerlevel10k</a>，因为我们用的是Oh My Zsh，所以安装方法也用Oh My Zsh对应的方法，引用下项目的README中的安装方法：</p><blockquote><p><strong>Oh My Zsh</strong></p><figure class="highlight awk"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs awk">git clone --depth=<span class="hljs-number">1</span> https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/romkatv/</span>powerlevel10k.git <span class="hljs-variable">$&#123;ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom&#125;</span><span class="hljs-regexp">/themes/</span>powerlevel10k<br></code></pre></div></td></tr></table></figure><p>Users in mainland China can use the official mirror on <a href="http://gitee.com">gitee.com</a> for faster download.<br />中国大陆用户可以使用 <a href="http://gitee.com">gitee.com</a> 上的官方镜像加速下载.</p><figure class="highlight awk"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs awk">git clone --depth=<span class="hljs-number">1</span> https:<span class="hljs-regexp">//gi</span>tee.com<span class="hljs-regexp">/romkatv/</span>powerlevel10k.git <span class="hljs-variable">$&#123;ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom&#125;</span><span class="hljs-regexp">/themes/</span>powerlevel10k<br></code></pre></div></td></tr></table></figure><p>Set ZSH_THEME=“powerlevel10k/powerlevel10k” in ~/.zshrc.</p></blockquote><p>很贴心给了镜像。简单来讲就是运行给出的指令，然后改一下<code>.zshrc</code>就行了，下一次打开zsh时会跳出主题的一个配置过程，按照指示依次选定想要的样式，最后保存配置，ZSH主题就配置完成了，效果就和上面yakuake截图中一样。</p><p>至于插件，只需要autojump, zsh-autosuggestions和zsh-syntax-highlighting就行，安装方法可以参照另一个博主的<a href="https://www.zrahh.com/archives/167.html">这篇文章</a>，个人觉得这几个足矣。其中<code>autojump</code>在Linux下的安装不用那么麻烦，而且还可能不见得装的上，manjaro直接从AUR装就可以了，或者<code>archlinuxcn</code>中带了。</p><p>三个ZSh插件功能如下：</p><ul><li><strong>autojump</strong> 任何位置使用<code>j xxx</code>即可跳转到对应的目录，而且不用写全目录名称。前提是这个目录之前访问过。</li><li><strong>zsh-autosuggestions</strong> 会记住之前的命令输入历史，在输入命令时自动显示出过去输入过的命令，按右方向键<code>&gt;</code>即可自动填充。</li><li><strong>zsh-syntax-highlighting</strong> 会给输入的命令高亮，输错了的命令会显示成红色。</li></ul><p>效果如下图：</p><p><img src="2021-02-21T003034.png" alt="2021-02-21T003034" /></p><h2 id="输入法配置和主题"><a class="markdownIt-Anchor" href="#输入法配置和主题"></a> 输入法配置和主题</h2><p>最后来讲下输入法的问题吧，毕竟打字还是要个中文输入法的。个人使用的是Fcitx，虽然Fcitx 5已经出了，但还是用的4。</p><p>安装就不说了，主题依然是使用了一个魔改后的主题，受害者是Material主题，来源已经不清楚了，应该是从Github上找到。魔改后的效果如下图，附<a href="https://drive.google.com/file/d/192uBLNoPpNklZr8RbhuOxnrVmIXvvMAu/view?usp=sharing">下载链接</a>，解压后放置到<code>~/.config/fcitx/skin/</code>，然后去Fcitx设置中改主题即可。</p><p><img src="2021-02-21T003807.png" alt="2021-02-21T003807" /></p><p>至于输入法的配置，个人使用的是LibPinyin，另外在LibPinyin的设置中开了一些模糊音和词库，以及添加了搜狗的细胞词库，总的来说还凑合，词的提示不怎么智能就是了。云拼音建议打开。</p><p>另外，一定要更新Fcitx以及其他的包到新版，旧的版本可能会有问题，比如细胞词库导入不了，或者云拼音出不来等等。</p><hr /><p>至此告一段落吧，笔者是个只有兴起才会写写的懒人…<br />不过最近更新主题之后，评论功能也开了～</p>]]></content>
    
    
    <categories>
      
      <category>Linux - Theme</category>
      
    </categories>
    
    
    <tags>
      
      <tag>主题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning中大数据集加载的技巧摘要</title>
    <link href="/2020/09/03/Deep-Learning%E4%B8%AD%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%8A%A0%E8%BD%BD/"/>
    <url>/2020/09/03/Deep-Learning%E4%B8%AD%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%8A%A0%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<h2 id="引入"><a class="markdownIt-Anchor" href="#引入"></a> 引入</h2><p>近期在处理PCAP格式的网络抓包数据集的时候，在数据集处理方面遇到了不少的问题，主要表现为数据集巨大，有几十GB的大小，由于调试的需要免不了要多次从中提取出数据来进行训练。所以在此简单记录和总结一下其中使用到、学习到的一些处理方法。</p><!---more---><h2 id="选择合适的读取方式"><a class="markdownIt-Anchor" href="#选择合适的读取方式"></a> 选择合适的读取方式</h2><p>库与库之间的体制是不能一概而论的，有的库在加载数据的时候有着先天的劣势，读取同样的数据就是比其他的库要慢。在进行大量数据的读取的时候就不得不考虑使用哪一个库，例如在读取PCAP时，使用scapy就是比dpkg要慢很多，而且从磁盘中读取时速度可能会相差几十倍。类似的，使用某些库进行CSV读取也可以获得更快的速度，甚至更小的内存占用。</p><h2 id="缓存"><a class="markdownIt-Anchor" href="#缓存"></a> 缓存</h2><p>最简单的提升速度的方式是在存在大量IO操作和预处理的数据加载之后，使用某种方式进行缓存。</p><p>最简单的一个实现是使用Python的pickle模块，它可以快速地将一个Python中的基本量序列化到文件中（或者也可以用来序列化后进行网络传输等操作），不过它是Python专有的，其他语言不能读取。另外也可以使用json模块，将Python列表或字典转换成json文件，但是加载速度会比使用pickle慢。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cache_save</span>(<span class="hljs-params">variable, cache_file</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    create cache for variable using pickle</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :param variable: variable need to be cached</span><br><span class="hljs-string">    :param cache_file: path to cache file</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(cache_file, <span class="hljs-string">&quot;wb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>            pickle.dump(variable, f, <span class="hljs-number">0</span>)<br>    logger.info(<span class="hljs-string">&quot;Cache is saved to %s&quot;</span>, cache_file)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cache_load</span>(<span class="hljs-params">cache_file</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    recover variable from cache file</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :param cache_file: path to cache file</span><br><span class="hljs-string">    :return: recovered variable</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(cache_file, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        variable = pickle.load(f)<br>    logger.info(<span class="hljs-string">&quot;Cache is loaded from %s&quot;</span>, cache_file)<br>    <span class="hljs-keyword">return</span> variable<br></code></pre></div></td></tr></table></figure><p>使用缓存时另外一个比较棘手的问题是何时从缓存中加载，而何时从数据集中重新进行读取？</p><p>如果刚对数据集进行了一定的修改，显然应该重新加载一遍数据集，但是如果加载的代码进行了一定的变更呢？如何决定是否需要重新从数据集中加载一遍？这个问题是无法预先回答的，因为很难预测一些更改是否对数据集的加载结果产生了影响。</p><p>比较简单的折衷方案是始终尝试从缓存中读取，而在需要重新建立缓存时手动删除缓存文件；又或者是在代码中添加一个BOOL变量来控制。（总之笔者还没有找到一个一劳永逸的解决方案）前者通常要求尝试检查文件是否存在，因此可以通过一个try_load来完成这一个操作。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cache_try_load</span>(<span class="hljs-params">cache_file, load_function, *args</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    try to load variable from cache file.</span><br><span class="hljs-string">    if not exist, call `load_function`.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    :param cache_file:</span><br><span class="hljs-string">    :param load_function:</span><br><span class="hljs-string">    :param args:</span><br><span class="hljs-string">    :return:</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">return</span> cache_load(cache_file)<br>    <span class="hljs-keyword">except</span> FileNotFoundError:<br>        variable = load_function(*args)<br>        cache_save(variable, cache_file)<br>        <span class="hljs-keyword">return</span> variable<br></code></pre></div></td></tr></table></figure><p>使用这样的方法就推荐事先将一项数据的加载过程写成一个函数，以返回值作为加载的结果。</p><h2 id="tfdata中在运行时载入数据"><a class="markdownIt-Anchor" href="#tfdata中在运行时载入数据"></a> tf.data中在运行时载入数据</h2><p>通常学习通过使用<code>tf.data</code>来加载数据集的时候，大都是从自内存中的数据（数组）来构建<code>tf.data.Dataset</code>开始的。这就要求了所有数据一定要事先存在于内存之中，从而会增加内存的占用。</p><p>因此个人觉得在处理一些大数据集的时候就不应该使用<code>tf.data.Dataset.from_tensor_slices</code>或<code>tf.data.Dataset.from_tensors</code>等函数，而应该使用<code>tf.data.Dataset.from_generator</code>这样的函数，使用Python Generator来完成数据集的载入。</p><p>Tensorflow在处理一个通过生成器来创建的数据集时，总是需要读取数据的时候才载入一系列数据（也包括使用shuffle buffer时，会载入预定的数量到内存），而不会读入整个数据集。大部分时候深度学习的数据集都是逐项的，相互之间没有计算关系，所以可以逐项载入。</p><p>不过如果需要综合处理整个数据集的时候使用Generator可能就会遇到一些问题，例如对抓包数据集中的流提取统计信息，就需要持续统计处理才能得到最终的结果。但对于这样的问题，可以通过和上述的缓存配合来解决。可以先进行统计、提取出训练用的特征，逐项存入一个CSV文件中，再通过逐行读入CSV的生成器来加载数据集。</p><h2 id="编码实践中的建议"><a class="markdownIt-Anchor" href="#编码实践中的建议"></a> 编码实践中的建议</h2><p>对于大数据的加载和处理往往比想象中的要复杂、困难许多，有些费时，代码的组织可能成为一个大问题（至少对于笔者最近的开发情况来说）。</p><p>在进行大数据集读取，尤其是同时还需要进行一些数据处理工作的时候，有以下这些建议：</p><ul><li><p><strong>使用通用的、易于扩展的结构</strong>：如果数据集可能出现变动或调整，例如出现数据集替换，或者比较常见的数据集扩展（加入一些自定义的数据集，也许不使用和源数据集一样的保存格式），就需要注意导入的方式一定要具有一定的扩展性，否则之后问题会变得很棘手。</p></li><li><p><strong>分离数据载入、数据处理等步骤</strong>：各个功能的实现不要草草合并在几个函数中，一定要注意各个部分功能的隔离。数据集的读取部分（IO）、处理部分（计算）、最终数据集的导出或者创建一个tf.data.Dataset数据集类，最好进行一定程度的分隔，方便进行替换。这样做的另一个好处是对于每一个部分的处理结果都可以进行缓存，这样如果之前几步没有更改，就可以跳过之前的步骤，从缓存中导入处理结果。另外这么做也有利于增强上一条的通用性、扩展性。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Systemd服务脚本</title>
    <link href="/2020/07/07/Systemd%E6%9C%8D%E5%8A%A1%E8%84%9A%E6%9C%AC/"/>
    <url>/2020/07/07/Systemd%E6%9C%8D%E5%8A%A1%E8%84%9A%E6%9C%AC/</url>
    
    <content type="html"><![CDATA[<h2 id="序"><a class="markdownIt-Anchor" href="#序"></a> 序</h2><p>现在大多数发行版已经切换到了使用systemd进行服务管理，原本的service已经逐渐被废弃。</p><p>这次来整理下systemd下服务脚本的写法。</p><span id="more"></span><h2 id="路径"><a class="markdownIt-Anchor" href="#路径"></a> 路径</h2><p>systemctl的脚本存储在以下两个路径中：</p><ul><li><p><code>/usr/lib/systemd/system</code>： 系统服务，运行具有管理员权限。</p></li><li><p><code>/usr/lib/systemd/user </code>：用户服务，只有在用户登陆之后才开始运行。</p></li></ul><p>一般自定义的服务都以<code>*.service</code>结尾，存放在<code>/usr/lib/systemd/system</code>中即可，另一个使用比较少。</p><h2 id="脚本结构"><a class="markdownIt-Anchor" href="#脚本结构"></a> 脚本结构</h2><p>一个服务脚本由三个部分组成：<code>[Unit]</code>、<code>[Service]</code>和<code>[Install]</code>。</p><ul><li><code>[Unit]</code>：主要包含服务的说明。</li><li><code>[Service]</code>：定义了服务的主要内容（核心）。</li><li><code>[Install]</code>：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs service">[Unit]<br>...<br><br>[Service]  <br>...<br><br>[Install]   <br>...<br></code></pre></div></td></tr></table></figure><h2 id="参数字段"><a class="markdownIt-Anchor" href="#参数字段"></a> 参数字段<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></h2><h3 id="unit"><a class="markdownIt-Anchor" href="#unit"></a> [Unit]</h3><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs service">[Unit]<br>Description=test# 对于服务的说明文本<br>After=network.target# 表示服务需要在哪些服务之后启动<br>Before=xxx.service# 表示服务需要在哪些服务之前启动<br>Requires=xxx.service# 表明服务之间的强依赖关系<br>Wants=xxx.service# 表示服务之间的弱依赖关系<br></code></pre></div></td></tr></table></figure><p><strong>Requires - 强依赖</strong></p><p>在当前服务启动的时候，Requires列表下的服务也会被一起启动；如果Requires列表下某一个服务被停止，或者启动失败了，这一个服务也会被同时停止。所以Requires会产生很强的依赖关系。</p><p>Requires不能保证服务之间执行的顺序，当前服务和Requires中的服务可能同时被激活运行。</p><blockquote><p>i.e. If a unit foo.service requires a unit bar.service as configured with Requires= and no ordering is configured with After= or Before=, then both units will be started simultaneously and without any delay between them if foo.service is activated.<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p><p>在foo.service中定义了Requires=bar.service，表明foo.service依赖于bar.service，但是在启动的时候foo.service和bar.service完全可能同时开始运行，中间没有任何延迟。</p></blockquote><p>所以如果foo.service中定义了Requires=bar.service，启动的过程应该如下：</p><ol><li>检查<code>bar.service</code>是否启动。</li><li>如果<code>bar.service</code>没有启动，则启动bar.service。</li><li>如果<code>bar.service</code>已经启动（或经由2启动了），则可以启动<code>foo.service</code>。</li><li>如果在<code>foo.service</code>运行过程中<code>bar.service</code>终止了，则同时终止<code>foo.service</code>。</li><li>反过来<code>bar.service</code>终止了，对<code>foo.service</code>没有影响。</li></ol><p><strong>Wants - 弱依赖</strong></p><p>Wants的行为介于Requires和After之间。在一个服务被启动的时候，Wants列表下的服务也会被启动，但和Requires的区别是Wants下的服务即使启动失败、或者运行中出现了问题，也不会反过来影响当前服务的继续执行，因此被作为弱依赖。</p><p><strong>After和Before</strong></p><p>两者可以保证服务之间启动的顺序性，定义之后可以保证服务在某一个服务启动之后/之前启动。和Requires不同的是，After不会产生依赖关系，所以虽然在启动的时候要求After列表中的服务先启动，但是之后即使After列表中某一个服务停止了，当前服务也依然会继续运行。</p><p>注意在服务终止的时候，会依照相反的顺序终止。</p><blockquote><p>i.e. if a unit is configured with After= on another unit, the former is stopped before the latter if both are shut down.</p><p>如果foo.service中设定了After=bar.service，则在两个一起被终止的时候，foo.service会先于bar.service终止。</p></blockquote><p>比阿另外如果两个服务存在着After或Before中任意的关系，在一个服务被shutdown而同时另一个服务在start的时候，shutdown永远先执行。而当没有After或Before的时候，会是同时的。</p><p>同样的在foo.service中定义了After=bar.service，形式化描述这一个启动过程应该是这样的：</p><ol><li>检查<code>foo.service</code>是否启动。</li><li>如果<code>foo.service</code>启动了，则可以启动<code>bar.service</code>。</li><li>如果<code>foo.service</code>没有启动 ，则一直等待。</li><li>如果在<code>bar.service</code>或<code>foo.service</code>都启动了之后，某一方出现问题终止了，则都不会影响另一方。</li></ol><h3 id="service"><a class="markdownIt-Anchor" href="#service"></a> [Service]</h3><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs service">[Service]<br>Type=forking# 代表了服务的运行模式<br>User=user# 用户<br>Group=user# 用户组<br>KillMode=control-group# 指定systemd在停止服务时该怎么做<br>PIDFile=/usr/local/test/test.pid# 提供pid文件的绝对路径<br>Restart=always# 重启规则<br>RestartSec=10# 重启之前等待的秒数<br>ExecStart=/usr/local/test/bin/startup.sh# 执行内容<br>PrivateTmp=true# 分配独立的临时空间<br></code></pre></div></td></tr></table></figure><p><strong>Type - 运行模式</strong><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup></p><p>运行模式的关键词和效果主要有以下这些：</p><table><thead><tr><th>Type</th><th>效果</th></tr></thead><tbody><tr><td>simple</td><td>默认值。使用这一类型会使得systemd认为你的服务不会fork，所以认为服务是立即执行的，当前进程的结束即代表了整个服务程序结束运行，会识别为退出状态。所以这一类型适合于那些只有单进程，会持续运行直至主进程退出的程序。<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></td></tr><tr><td>forking</td><td>一般服务都是使用这一个类型。这一模式下systemd会认为当前的服务会进行fork，所以主进程的退出不一定就意味着整个服务已经结束，因为服务可能作为子进程在后台正常运行着。使用这一类型应该同时指定<code>PIDFile=</code>，以便systemd能够跟踪主进程。</td></tr><tr><td>oneshot</td><td>适用于只需要执行一次的服务、随后立即退出的服务。另外为了让systemd在服务退出之后仍然认为服务处于激活状态，需要同时设置，<code>RemainAfterExit=yes</code>。</td></tr><tr><td>notify</td><td>和simple相同，除了约定在服务就绪之后会向systemd发送一个信号，通知的实现由 <a href="http://libsystemd-daemon.so">libsystemd-daemon.so</a> 提供。</td></tr><tr><td>dbus</td><td>使用这一方式启动的时候，systemd通过指定的<code>BusName</code>是否出现在了<code>DBus</code>总线上来判断服务是否就绪。</td></tr></tbody></table><p><strong>User和Group - 执行身份</strong></p><p>指定服务运行的用户和用户组。</p><p><strong>KillMode - 如何停止</strong></p><p>（待补充）</p><p><strong>Restart - 重启规则</strong></p><p>决定了服务以怎样的模式重新启动。</p><table><thead><tr><th>Restart</th><th>效果</th></tr></thead><tbody><tr><td>no</td><td>默认。不会重启。</td></tr><tr><td>on-success</td><td>只有在服务正常退出（return 0）时才重启。</td></tr><tr><td>on-failure</td><td>在程序以任何非正常的方式退出时重启。</td></tr><tr><td>on-abnormal</td><td>只有在被信号终止或超时时，才重启。</td></tr><tr><td>on-abort</td><td>只有在收到没有被捕捉到的信号而终止时，才重启。</td></tr><tr><td>on-watchdog</td><td>只有在超时退出时，才重启。</td></tr><tr><td>always</td><td>不管什么原因，重启就对了。</td></tr></tbody></table><p><strong>各种Exec*字段 - 执行程序</strong></p><p>定义在服务的各个阶段分别执行什么指令，有以下这些：</p><table><thead><tr><th>Exec*</th><th>执行阶段</th></tr></thead><tbody><tr><td>ExecStart</td><td>启动服务</td></tr><tr><td>ExecReload</td><td>重启服务</td></tr><tr><td>ExecStop</td><td>停止服务</td></tr><tr><td>ExecStartPre</td><td>启动服务前</td></tr><tr><td>ExecStartPost</td><td>启动服务后</td></tr><tr><td>ExecStopPost</td><td>停止服务后</td></tr></tbody></table><h3 id="install"><a class="markdownIt-Anchor" href="#install"></a> [Install]</h3><figure class="highlight plaintext"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs service">[Install]   <br>WantedBy=multi-user.target<br></code></pre></div></td></tr></table></figure><p><strong>WantedBy</strong><sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></p><p>用于表示服务所属的target，从而配置开机启动。一般常用的只有<code>multi-user.target</code>和<code>graphical.target</code>（依赖于<code>multi-user.target</code>）。</p><h2 id="相关参考"><a class="markdownIt-Anchor" href="#相关参考"></a> 相关参考</h2><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>一篇系统性介绍的文章：<a href="https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html">Systemd 入门教程：实战篇</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>关于<code>After=</code>和<code>Requires=</code>区别的讨论：<a href="https://serverfault.com/questions/812584/in-systemd-whats-the-difference-between-after-and-requires">In systemd, what’s the difference between After= and Requires=? - Server Fault</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>啥都有的Arch Wiki：<a href="https://wiki.archlinux.org/index.php/Systemd_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">systemd (简体中文) - ArchWiki</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>关于simple和forking模式的区别：<a href="https://superuser.com/questions/1274901/systemd-forking-vs-simple/1274913">redhat enterprise linux - systemd forking vs simple? - Super User</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>一篇介绍了些参数的文章：<a href="https://www.cnblogs.com/wang-yc/p/8876155.html">Centos7 自定义systemctl服务脚本</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>聊一聊Linux发行版的问题</title>
    <link href="/2020/07/03/%E8%81%8A%E4%B8%80%E8%81%8ALinux%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2020/07/03/%E8%81%8A%E4%B8%80%E8%81%8ALinux%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>Linux的发行版本问题一直都是一个比较有争议的领域，也由此产生了一些不同的派别（试图引起派系斗争），不过我个人在体验了不少发行版之后倒是觉得发行版并不见的那么重要。可能真的到了一定程度，这种差异会消失，毕竟那些大佬都有能力自己组自己的Linux，有内核就行，还考虑啥发行版呢。<code>( ´◔ ‸◔')</code></p><p>本是同根生（指内核），相煎何太急～</p><p>所以，大家不如放弃偏见，团结一致，珍爱生命，远离ubuntu。<code>(╯°Д°）╯︵ /(.□ . \)</code></p><p>给个大纲：</p><ul><li>我的Linux简史（闲谈）</li><li>发行版问题<ul><li>一些体验一致的地方</li><li>一些体验不一致的地方</li></ul></li><li>具体谈几个发行版本的使用经历</li></ul><span id="more"></span><h2 id="我的linux简史"><a class="markdownIt-Anchor" href="#我的linux简史"></a> 我的Linux简史</h2><p>先来闲聊一下吧～不知道有没有人也有类似的经历呢～</p><p>从高中第一次接触Linux开始，直至今日已经尝试了不少的Linux发行版本。最早接触的发行版自然是ubuntu，毕竟它在国内的热度还是比较高的。</p><p>当时只是抱着玩一玩的心态，也可能是反复装Windows玩腻了。在上手后不久又出于某些原因开始学着部署OwnCloud，那个时候的部署方案还是Apache，照着网上的各种教程一点点地试错，还真的整出来了，这可能也是我早期Debug和资料搜索经验的由来。不过没想到的是我现在都还在用这么套云存储，虽然已经更迭到了Nextcloud，变为了Docker部署，还增添了许多性能优化，但是还是原本那个熟悉的环境，熟悉的流程。</p><p>之后则开始接触openSUSE，原因已经不得而知，但作为一个对于开发一无所知的萌新来讲，用Linux不过也只是玩玩。但那时候也熟悉了LEAP和Tumbleweed两个发行版，算是打了个基础吧。</p><p>真正正式接触到Linux则是到了大学，而我开始将Linux当作日用也仅仅只是仅半年的事情。由于经常接触软件的开发，在Linux环境下往往能更快地获得一个稳定、高效的开发环境，并且不容易遇到各种各样的奇葩又难以解决的兼容性问题，因此Linux的使用比例也越来越高。处于稳定性的需要，在这个时候开始接触起CentOS。当然CentOS固然老旧，但是稳定性的确不错，没有ubuntu里莫名其妙的Bug，防火墙也一应俱全（ufw？相比起来我觉得ufw设置的GUI过于鸡肋）。</p><p>但Linux的问题也是很明显的：硬件兼容性。换到了硬件层面，即使已经在大学学习了一点基础，也瞬间只能用一个字来形容——菜。硬件的兼容问题根本不是个人能够解决的，至少对于我这样刚入门的人来说根本无从下手。最突出的当属显示问题，有些是显卡驱动导致，有些则是应用程序、桌面启动器等的兼容性导致，当然也有许多我不知道的原因，那些问题就属于至今都还没解决的问题了。</p><p>所以如果想装Linux，买电脑前就应该调查好兼容性问题。</p><p>什么？虚拟机？那当我没说。</p><p>对于我来说是准备日用的，日常开个虚拟机，简直是作死。</p><h2 id="发行版问题"><a class="markdownIt-Anchor" href="#发行版问题"></a> 发行版问题</h2><p>差不多回归主题（想起标题了）。</p><p>用了一圈的发行版，最大的感受是：都一样。</p><p>事实上如果是纯粹的开发，任何Linux发行版本几乎都一样（至少在我所涉及到的范围之内），无非是安装方式的差距。如果一个开发已经需要依赖于某一个发行版本，换一个发行版就无法工作的话，这一个软件本身可能就是有问题的。</p><p>以OpenDayLight控制器为例，本来我们项目使用了从ODL官网下载的编译好的控制器版本，但是这一个控制器在ubuntu上各种报错，而换到CentOS就没有报错了。起初我认为是ubuntu不稳定的问题，但是后来继续实验还是出了问题。最终的解决方案是使用Maven从源码构建，这一版本的控制器用来配置SFC才是功能正常的，所以这锅并不在于ubuntu。</p><p>不过这种开发实际上比较特殊，也是我遇到的唯一一起发行版之间有实际差异的特例。更多情况下，我感受到的是一致性。</p><h3 id="发行版一致"><a class="markdownIt-Anchor" href="#发行版一致"></a> 发行版一致</h3><h4 id="包管理大同小异"><a class="markdownIt-Anchor" href="#包管理大同小异"></a> 包管理大同小异</h4><p>在各个发行版之前切换，最大的变化在与包管理系统可能不一样，但是实际上都类似。指令从<code>apt</code>到<code>zypper</code>，再到<code>yum</code>、<code>pacman</code>，命令在变参数在变，但做的都是类似的工作，常用的软件也还是可以在源里面找到。无非像CentOS这样的守旧派版本过于古老，但是从源码编译安装是一项基本的本领，Google一下源项目（基本在Github上），编译安装就是。</p><h4 id="snap与flatpak"><a class="markdownIt-Anchor" href="#snap与flatpak"></a> snap与flatpak</h4><p>另外一个减弱对于发行版本的依赖的则是<code>snap</code>和<code>flatpak</code>的兴起。其中我自然是更加倾向于<code>flatpak</code>，<code>snap</code>毕竟长期服务于ubuntu，如果<code>snap</code>排斥其他发行版开始闭门造车，我想我会毫不犹豫地抛弃它。这类工具最大的特点即是跨发行版，原本的目的就在于另软件可以运行于任意发行版本之上，为此付出的代价是占用更多的存储空间（真的不是一般地大，到头来不同平台的包一多，可能会占据系统存储的半壁江山，但是这部分也就牺牲10～20GB不等，如今也还可以接受）。常用的一些软件在上面都有发布，如今越来越多的应用也在增加这一发布方式。</p><h4 id="docker"><a class="markdownIt-Anchor" href="#docker"></a> Docker</h4><p>Docker：你宿主是啥发行版，管我容器什么事情？</p><p>另一个因素则是<code>docker</code>的运用。在我看来如果你真的熟悉一个服务的部署，那将他转移到Docker上应该是一件轻而易举的事情，因为它本质就是一个类似Shell脚本的存在。仅考虑数据的存储，而通过Docker完全忽略发行版本之类的问题、再部署问题，不用为哪一天系统崩了、云主机到期不想续费了而丢失已经配好的系统服务而发愁，夸张点说真的是一劳永逸的事情。</p><h3 id="发行版差异性"><a class="markdownIt-Anchor" href="#发行版差异性"></a> 发行版差异性</h3><h4 id="更新频率"><a class="markdownIt-Anchor" href="#更新频率"></a> 更新频率</h4><p>每天刷新软件源都能有更新，从头到尾都是船新版本，这样的Linux你喜欢吗？</p><p>这就是典型的openSUSE Tumbleweed的更新模式了。求稳定肯定还是LEAP，更新少，一般只做一些安全更新，至少我所使用的经历中几个礼拜下来都不会有啥大的更新。</p><p>很多发行版本在更新上是由区别的，有的软件包太老（典型的例子就是CentOS，但是它就应该拿来跑跑服务，本来的目标、服务群体就不一样），有的又太新，导致可能不稳定。更新周期以及软件版本之类的一般都会有发布，在<a href="https://distrowatch.com/"><br />DistroWatch</a>上往往能够找到最新的消息。一个最为核心的问题可能是内核版本，特别是有些硬件（比如我使用的AX200网卡），对于内核版本有要求，太早的不能驱动。</p><h4 id="桌面环境"><a class="markdownIt-Anchor" href="#桌面环境"></a> 桌面环境</h4><p>要说各个发行版间的不同，桌面环境可能是最大的了。各个发行版本默认支持的桌面版本是不同的，如ubuntu就仅官方支持一个Gnome，而openSUSE则支持多个桌面环境，不过个人认为重点还是在KDE的支持上。一般官方支持的桌面环境的兼容性会更好，遇到各种问题的可能性也比较少。</p><p>另外一个很常见的衍生问题是系统的睡眠、休眠问题，很多时候硬件的不兼容会在这里有所体现，可能出现不能睡眠、睡眠后无法唤醒等各类匪夷所思的情况，这也是我目前面临的主要问题，所以要测试一台新买的笔记本的硬件是否和Linux兼容较好，可以从这里开始。</p><h4 id="社区"><a class="markdownIt-Anchor" href="#社区"></a> 社区</h4><p>这一个问题在国内很大程度受到了语言的限制……国内的很多教程或问题的解决，亦或是软件、服务的安装部署教程，直指的发行版就是ubuntu，所以现实就是一般问题在ubuntu下更容易找到中文的解决方案。当然如果你英语不错，也会使用英语来搜索关键字，那这一问题会得到一定的缓解。有些发行版本虽然国内不温不火，甚至于冷门，但在国外可能还是很活跃的，一定要正视这一个社区环境的差异。</p><h3 id="分析几个发行版的具体使用体会"><a class="markdownIt-Anchor" href="#分析几个发行版的具体使用体会"></a> 分析几个发行版的具体使用体会</h3><h4 id="opensuse-最强btrfs支持"><a class="markdownIt-Anchor" href="#opensuse-最强btrfs支持"></a> openSUSE - 最强Btrfs支持</h4><p>openSUSE可以说是比较正统的几个Linux发行版中我最为喜欢的一个了，虽然实际上的使用体验可能和切换到fedora这样同样的rpm系发行版会很类似，但是openSUSE也有着自己的亮点。</p><p>最重要的我觉得还是<strong>完整的Btrfs支持</strong>。我相信openSUSE有着所有Linux发行版里面最好的Btrfs支持，最重要的是一切都是开箱即用的。Btrfs的快照备份对于爱折腾的人来说尤为重要，这一点可以参照之前的博客，对Btrfs有比较详尽的介绍。使用Btrfs快照备份十分迅速，并且通过配置snapper（这个也是默认自带的）就可以设置定时备份、定时清理旧快照，一切都组织有序。在使用zypper（openSUSE的包管理命令）安装软件包的时候也会自动创建快照。更为重要的是启动的时候就可以选择从已有的某一个快照中以只读形式启动，这样随时都可以恢复到之前的某一个状态，如果你检查了下这一个快照下运行正常，你就可以通过rollback恢复到当前的快照，十分快速地从系统问题中恢复。</p><p>另一点则是Yast，Yast的确是一个十分便捷的工具，也受到很多人追捧（估计维护人员居多），不过个人而言并没有感觉到它是多么地不可替代，不过有一个集成的配置中心的确感到很便捷。</p><p>openSUSE是有LEAP和Tumbleweed两个版本的，LEAP十分稳定，但是包也完全不陈旧，可以说是十分适中的一个存在。Tumbleweed的滚动更新也蛮吸引人，但是更新频率有点过于频繁。由于有快照的加持，即使Tumbleweed更新较为激进，但是也基本不用担心系统滚挂，可以说openSUSE便捷且开箱即用的快照支持是Tumbleweed用户的一颗定心丸。</p><p>在国内使用openSUSE有一个很大的问题：镜像。openSUSE的总镜像是在德国的（本来就是源于德国的发行版），并且借助metalink技术，使得即使从总镜像更新，在下载的时候也会使用本地就近的镜像进行加速。这一模式理论上很美好，但是实际上和总镜像的链接经常被墙或者速度缓慢，所以更新速度十分令人着急，所以迫不得已还是需要使用镜像。问题是有些源没有镜像，还不得不从官方获取，所以网差的时候可能根本无法更新这些软件源，可以说十分劝退。</p><h4 id="manjaro-背靠arch"><a class="markdownIt-Anchor" href="#manjaro-背靠arch"></a> Manjaro - 背靠Arch</h4><p>Manjaro是我目前的主力系统。让我留恋于这一个系统的主要原因是来自Arch一侧的社区所带来的众多软件包，其中AUR占据了十分重要的地位。</p><p>或许是在尝试了众多发行版本之后本身也觉得没什么意思，所以我更倾向于寻找一个满足日用要求的（当然这个日用其实包括了很多开发环境），便捷的系统，而Manjaro真的适合思想逐渐佛系的我。软件安装方便，基本AUR中都有你想要的，也不需要折腾，感谢这些dalao的维护想要的软件基本已经准备好了。另外Manjaro的内核管理也比较方便，通过GUI可以随意切换内核。从寻找桌面操作系统的角度，Manjaro是一个不错的选择。</p><p>在Manjaro上使用Btrfs，你需要使用timeshift（自带，而非openSUSE中的snapper）进行日常的备份操作。timeshift虽然也不差，但是Manjaro并不自带从快照中启动的功能，所以我往往是进单用户模式去回滚。</p><p>Manjaro还有的一点优势是相较于其他派系的延伸版本，比如从Debian和ubuntu之间的差异，Arch和Manjaro的差异还是不大的，给人的使用体验和带了桌面的Arch没啥太大的不同（当然我目前还没使用过Arch，但是教程普遍通用，相较于别的派生关系，这个通用性蛮高了）。众所周知，Arch的Wiki里啥都有，背靠着Arch的社区也是令我选择它的一个重要原因。</p><p>但是个人觉得，使用Arch系会有一个问题：没有对应的Server。如果你用fedora，可能很容易和RedHat或者CentOS对应起来，这样用起服务器来的连贯性还是很好的。但是Arch就缺乏这样一个对应，我所了解的范围内，用Arch作为服务器的公司应该是少数，一些云服务器也不提供这一镜像。</p><h4 id="centos-默默无闻但坚实的后台"><a class="markdownIt-Anchor" href="#centos-默默无闻但坚实的后台"></a> CentOS - 默默无闻但坚实的后台</h4><p>我的所有云服务器，无脑CentOS。一是相信它的稳定性（虽然稳定性这种东西，真的用起来就是玄学，还真没怎么感受到），二是习惯问题，用多了再部署起来就不用查太多资料。因为和RedHat对应，在各类服务的部署方面的教程比较丰富和完整。而作为一个服务部署的宿主机，因为我为了复用，大部分的服务都制作成了Docker，所以CentOS的包即使再老旧，对我的影响也不会太大。</p><h4 id="ubuntu-一言难尽"><a class="markdownIt-Anchor" href="#ubuntu-一言难尽"></a> ubuntu - 一言难尽</h4><p>说起ubuntu心情蛮复杂的，虽然实际用起来跟我的总体认知一样：同为Linux用起来能差多少。但是因为ubuntu的公司风评不好，导致我时不时不免还是有些怀疑：这个程序为什么有问题，会不会是发行版的问题？（当然这种“发行版的问题”也包括某一发行版本的配置方式比较特殊，需要按照专门的教程）。</p><p>总之结果就是心理上还是不会优先考虑ubuntu。另一个原因可能更加现实一点：我需要KDE环境，但是ubuntu没有正式以KDE作为发行版。我知道有Kubuntu和KDE neon，但是非官方支持的桌面兼容性、稳定性还是值得商榷的。</p><p>至于作为服务器不使用它则是出于防火墙方面ufw鸡肋的缘故，firewalld配置起来还是更加合理且灵活些。</p>]]></content>
    
    
    <categories>
      
      <category>综合</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>KDE桌面美化指南 Part 1</title>
    <link href="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/"/>
    <url>/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>在经历了Linux环境的持续动荡之后，终于再一次配好了博客的环境。<br />在系统变更的过程中更迭了多次不同的发行版本，也尝试了许多次的主题美化，最终桌面美化的结果也大致稳定下来。</p><p>同时，用了半个学期的Manjaro终究还是有硬件兼容问题，所以重新回归了openSUSE Tumbleweed，正好借重新配置的机会谈一谈KDE下的主题美化，记录下配置过程。</p><p>目前Manjaro这边则已经配置完全，用Manjaro的状况来展示下最终的预期效果：</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/manjaro-final.png" class="" title="manjaro-final"><span id="more"></span><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/dock-view.png" class="" title="dock-view"><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/switch-virtual-desktop.png" class="" title="switch-virtual-desktop"><h2 id="why-kde"><a class="markdownIt-Anchor" href="#why-kde"></a> Why KDE?</h2><p>国内应为ubuntu的热度一直居高不下，所以很多时候接触的往往是Gnome桌面环境，当然在早一些可能是已经凉凉的Unity（比如我最初接触的就是Unity）。<br />之所以选择KDE，主要还是应为以下几个原因：</p><p><strong>1. KDE拥有真正充分的可定制性</strong></p><p>你会发现在Gnome下，一个图标换起来都很麻烦。</p><p><strong>2. KDE Connect太香了</strong></p><p>你不知道KDE Connect? 不了解下？<br />能衔接上一部分手机的生态，对于改善日常的Linux体验还是有不小的提升的，尤其是需要互发文件的时候。</p><h2 id="初始桌面"><a class="markdownIt-Anchor" href="#初始桌面"></a> 初始桌面</h2><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/kde-init-desktop.png" class="" title="kde-init-desktop"><p>相对来说，openSUSE的初始桌面其实也满不错的～</p><h2 id="kde-store"><a class="markdownIt-Anchor" href="#kde-store"></a> KDE Store</h2><p>首先推荐KDE Store：<a href="https://store.kde.org">https://store.kde.org</a><br />类似的Gnome也有主题站点。</p><p>里面的内容和KDE下各类设置&gt;获取主题中的内容是一致的，从中可以方便地寻找好的主题。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/kde-store.png" class="" title="kde-store"><h2 id="step-1-主题配置"><a class="markdownIt-Anchor" href="#step-1-主题配置"></a> Step 1. 主题配置</h2><p>KDE设置中即提供了一系列的主题相关的配置，决定了总体的桌面风格，所以第一部即设置好这一系列的配置。以下的配置项如果找不到，只需要在设置&gt;搜索栏搜索即可。</p><h3 id="1-全局主题"><a class="markdownIt-Anchor" href="#1-全局主题"></a> 1. 全局主题</h3><p>全局主题使用<a href="https://github.com/vinceliuice">vinceliuice</a>的McMojave LAF，这位国人dalao真的作了相当多很赞的主题QwQ。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/mocmojave-laf.png" class="" title="mocmojave-laf"><p>比较好的主题普遍都会有黑白两种不同的版本，这个按照个人的喜好选择。个人选择了黑系的主题，应为经常半夜写代码所以白色会觉得刺眼 <code>(ノへ￣、)</code> ，效果如下。全局主题会替换掉下面的Plasma样式、应用样式、颜色、窗口装饰以及图标，算是一个总体的配置方案。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/mocmojave-laf-apply.png" class="" title="mocmojave-laf-apply"><p>需要注意的是直接通过设置提供的下载会比较慢，推荐配置好代理再下载。</p><h3 id="2-plasma样式"><a class="markdownIt-Anchor" href="#2-plasma样式"></a> 2. Plasma样式</h3><p>理论上讲，应用了全局主题之后，在设置&gt;Plasma样式中应该已经转变为了McMojave主题。</p><h3 id="3-应用样式"><a class="markdownIt-Anchor" href="#3-应用样式"></a> 3. 应用样式</h3><p>之前的设置都是正对全局的，比如你的各类菜单，以及你的桌面面板都会受以上的配置影响，而应用样式主要决定应用内的显示效果。<br />应用样式选择Kvantum-dark，之后会对Kvantum主题进行配置。</p><h3 id="4-gnomegtk-应用程序主题"><a class="markdownIt-Anchor" href="#4-gnomegtk-应用程序主题"></a> 4. GNOME/Gtk 应用程序主题</h3><p>这一个主题主要是影响使用GTK的程序的，KDE是Qt党，所以之前的配置大多只针对Qt有效。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/gtk-theme.png" class="" title="gtk-theme"><h3 id="5-图标主题"><a class="markdownIt-Anchor" href="#5-图标主题"></a> 5. 图标主题</h3><p>比较特殊的是只要应用了McMojave这一个全局主题，图标就都空了，可能是它应用的图标主题没安装。</p><p>推荐的图标主题主要有以下几种，当然都可以在设置&gt;图标中联网获取和设置。</p><p><strong>La Capitaine</strong></p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/la-capitaine.png" class="" title="la-capitaine"><p><strong>McMojave-circle</strong></p><p>这一个主题的好处是缺失的图标会从numix-circle中继承，这样你只需要同时安装好numix-circle，就可以补全一部分缺失的图标。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/McMojave-Circle.png" class="" title="McMojave-Circle"><h2 id="step-2-设置kvantum"><a class="markdownIt-Anchor" href="#step-2-设置kvantum"></a> Step 2. 设置Kvantum</h2><p>首先安装Kvantum Manager。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">sudo zypper in kvantum-manager kvantum-manager-lang<br></code></pre></div></td></tr></table></figure><p>然后需要安装一个Kvantum主题，这边依旧选择McMojave主题，可以从<a href="https://store.kde.org/p/1304957">KDE Store下载</a>。</p><p>之后将下载下来的<code>tar.xz</code>压缩包解压，然后打开Kvantum Manager，选择这一个文件夹，安装主题。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/kvantum-install.jpg" class="" title="kvantum安装主题"><p>接着将主题设置为McMojave，开始调整一些主题配置。在 合成&amp;一般外观 里面选择忽略非活动状态，并降低窗口和菜单的透明度，即可获得很好的磨砂效果。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/kvantum-setting.png" class="" title="kvantum设置"><h2 id="step-3-桌面dock和插件配置"><a class="markdownIt-Anchor" href="#step-3-桌面dock和插件配置"></a> Step 3. 桌面Dock和插件配置</h2><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">zypper in latte-dock<br></code></pre></div></td></tr></table></figure><p>目前（写作时）latte-dock的版本还只是0.9，为了获取悬空的效果所以实际安装了从Git源码编译的0.10版本，这一个版本应该不久就会正式发布。</p><p>接下来启动Latte Dock，并设置好它的开机启动（KDE中搜索”自动启动“应用），然后对Latte Dock的外观进行一些配置。</p><p>现在你可以在桌面上 右键&gt;添加部件，来为Latte Dock添加一些小部件，同样的你可以点击下方的按钮联网获取新的小部件。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/add-widget.png" class="" title="add-widget"><p>latte-dock只需要装一个额外的小部件：</p><ul><li><strong>Latte Seperator</strong>：Latte Dock上分隔用的小横线</li></ul><p>另外的部件都是用于顶栏的，从左到右使用到的小部件分别是：</p><ul><li><strong>Application title</strong>：显示当前的应用名称，推荐改下设置，只显示应用名。</li><li><strong>Window AppMenu Applet</strong>：这一个插件<strong>不能在设置里安装</strong>！需要编译安装，幸运的是openSUSE的软件源中自带了，通过<code>sudo zypper in applet-window-appmenu</code>安装即可。</li><li><strong>颜色拾取器</strong>：自带的。</li><li><strong>Netspeed Widget</strong>：网速显示。</li><li><strong>系统符合查看器</strong>：自带的，不过为了适合主题要改下其设置，调整下颜色方案。</li><li><strong>Weather Widge</strong>：一个UI不错的天气插件，特别是带了磨砂后看起来很赞。需要设置以下地理位置，并且勾上 <code>Appearance&gt;Render meteogram for yr.no</code>，否则雨量的图形会是一片白的背景。</li></ul><blockquote><p>Warning: <code>yr.no</code>更新了网页之后，<code>Weather Widge</code>插件没有更新，已经废了，推荐使用插件中另一个<code>OWM</code>天气站点。</p></blockquote><ul><li><strong>系统托盘</strong>：自带。</li><li><strong>Event Calendar</strong>：可以同步Google日历。需要设置下时间的格式等，也同时带有类似的天气界面。</li></ul><p>按照以上的配置后的顶栏效果如下：</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/top-bar-final.png" class="" title="top-bar-final"><p>接下来对Latte Dock进行配置，把想要的应用拖进取，左边添加一个自带的全屏形式的应用程序面板，右边则添加一个虚拟桌面调度器。</p><img src="/2020/06/30/KDE%E6%A1%8C%E9%9D%A2%E7%BE%8E%E5%8C%96%E6%8C%87%E5%8D%97/latte-dock-final.png" class="" title="latte-dock-final"><h2 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h2><p>以上主要设置了一下整体的主题和Kvantum主题，并添加了一些桌面插件，整理了桌面的外观。<br />目前一个大致的主题已经有了，其他还有一些细节的配置，主要还有以下这些：</p><ul><li>Dolphin的外观</li><li>Yakuake的主题配置</li><li>字体调整</li><li>Fcitx主题调整</li><li>终端主题的配置</li><li>KDE动画效果的调整</li><li>触摸板手势</li><li>应用、桌面、活动切换的配置</li><li>屏幕边缘动作</li><li>…（还差亿点）</li></ul><p>这些就之后再说～<br />想到这里突然又想继续用之前的Manjaro了<code>(￣ε(#￣)☆╰╮o(￣皿￣///)</code>。</p><p>真的全部配置完还是不容易，所以要好好珍惜系统，远离ubuntu，选用支持Btrfs的系统，特别是openSUSE这样带有业界最好的原生Btrfs快照备份设置的系统，设置好Btrfs备份，并按时做额外的分区备份。<code>（づ￣3￣）づ</code></p>]]></content>
    
    
    <categories>
      
      <category>Linux - Theme</category>
      
    </categories>
    
    
    <tags>
      
      <tag>主题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Btrfs文件系统</title>
    <link href="/2020/04/01/Btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/04/01/Btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<p>Btrfs文件系统已经逐渐被各种Linux发行版本支持，虽然其似乎还存在一些小问题（unstable），但是在其各种诱人的功能面前似乎并不那么重要。<br />由于文件系统事关重大，弄不好容易丢失数据，还是需要熟悉之后再操作，做好额外备份。</p><span id="more"></span><h2 id="写时复制"><a class="markdownIt-Anchor" href="#写时复制"></a> 写时复制</h2><p>写时复制（Copy-on-write, CoW）指了在多个调用者请求相同资源时，只有在某个调用者试图修改资源的内容时，系统才会为其复制一份专用副本。这样没有写操作的时候，就不会有多余的副本被创建。<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup><br />CoW的缺点之一在于对于像VM镜像、数据库文件这样的就地更改（updated-in-place）的文件，会导致写入<strong>碎片化</strong>。<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>所以对于这一类数据，不妨建一个子卷然后禁用CoW来储存他们。（别忘了修改<code>fstab</code>）</p><p>Btrfs默认启用写时复制，要停止使用写时复制，使用<code>nodatacow</code>选项，但是这一更改只会影响新创建的文件，对于已有文件（夹）使用下列命令进行修改，但仍存在一些细节问题，使用前务必参见参考资料中关于此节的详细描述<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">chattr +C &lt;/path/to/file/or/folder&gt;<br></code></pre></div></td></tr></table></figure><h2 id="子卷subvolume"><a class="markdownIt-Anchor" href="#子卷subvolume"></a> 子卷（Subvolume）<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup></h2><p>Btrfs通过Subvolume来实现在备份时排除某些文件夹。</p><h3 id="挂载子卷"><a class="markdownIt-Anchor" href="#挂载子卷"></a> 挂载子卷</h3><p>通过设置挂载的选项可以挂载指定的子卷：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">mount -o subvol=&lt;subvol&gt; &lt;device&gt; &lt;mount_path&gt;<br></code></pre></div></td></tr></table></figure><h3 id="子卷的修改操作"><a class="markdownIt-Anchor" href="#子卷的修改操作"></a> 子卷的修改操作</h3><h4 id="列出子卷"><a class="markdownIt-Anchor" href="#列出子卷"></a> 列出子卷</h4><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">btrfs subvolume list -p path<br></code></pre></div></td></tr></table></figure><p>使用后会列出对应<code>path</code>下的所有子卷，其数量可能会很多，因为所有的快照也以subvolume的形式储存，有意思的是Docker镜像也被保存为了subvolume：</p><h4 id="创建子卷"><a class="markdownIt-Anchor" href="#创建子卷"></a> 创建子卷</h4><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">btrfs subvolume create &lt;/path/to/subvolume&gt;<br></code></pre></div></td></tr></table></figure><blockquote><p>这里的<code>path</code>指的是子卷的绝对路径，比如当前挂载了<code>@</code>到<code>/mnt/@</code>目录下，则使用路径<code>/mnt/@/home</code>创建出来的子卷为<code>@/home</code>。</p></blockquote><h4 id="删除子卷"><a class="markdownIt-Anchor" href="#删除子卷"></a> 删除子卷</h4><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">btrfs subvolume delete /path/to/subvolume<br></code></pre></div></td></tr></table></figure><blockquote><p>如果只移除文件目录，而不使用<code>btrfs subvolume delete</code>命令并不会真正删除一个子卷。</p></blockquote><h4 id="默认子卷"><a class="markdownIt-Anchor" href="#默认子卷"></a> 默认子卷</h4><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">获取默认子卷</span><br>btrfs subvolume get-default /<br><span class="hljs-meta prompt_"># </span><span class="language-bash">设置默认子卷</span><br>btrfs subvolume set-default &lt;subvolume-id&gt; /<br></code></pre></div></td></tr></table></figure><h4 id="临时挂载"><a class="markdownIt-Anchor" href="#临时挂载"></a> 临时挂载</h4><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">使用路径挂载</span><br>mount -t btrfs -o subvol=&lt;subvolume&gt; &lt;/mount/point&gt;<br><span class="hljs-meta prompt_"># </span><span class="language-bash">使用<span class="hljs-built_in">id</span>挂载</span><br>mount -t btrfs -o subvolid=&lt;id&gt; &lt;/dev/device&gt; &lt;/mount/point&gt;<br></code></pre></div></td></tr></table></figure><h3 id="btrfs子卷组织形式的探究"><a class="markdownIt-Anchor" href="#btrfs子卷组织形式的探究"></a> Btrfs子卷组织形式的探究<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup></h3><p>在openSUSE中查看当前的Btrfs的子卷，可能会显示大量的子卷，因为snapshot实际也是通过子卷来实现的，另外值得注意的是Docker镜像也被作为snapshot独立开了：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_">~$ </span><span class="language-bash">sudo btrfs subvolume list /</span><br>ID 256 gen 90 top level 5 path @<br>ID 257 gen 113574 top level 256 path @/var<br>...<br>ID 263 gen 113574 top level 256 path @/home<br>ID 266 gen 112569 top level 256 path @/.snapshots<br>ID 298 gen 98293 top level 257 path @/var/lib/docker/btrfs/subvolumes/ce11ad5...    # docker镜像<br>...<br></code></pre></div></td></tr></table></figure><p>其中<code>@</code>代表了文件系统的根（rootfs），但事实上它也仍然是一个snapshot，最顶层的卷是以0为标号的子卷，不过通常不使用。<br />同时默认的<code>/</code>同样也不是<code>@</code>子卷，一般也是某一个子卷，只是默认被挂载为了<code>/</code>，通过查看默认子卷可以得知：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_">~$ </span><span class="language-bash">btrfs subvolume get-default /</span><br>ID 267 gen 113599 top level 266 path @/.snapshots/1/snapshot  # 一个snapshot被作为默认子卷，挂载为了文件系统的 `/` 目录<br></code></pre></div></td></tr></table></figure><p>可见当前系统的<code>/</code>实际上是一个路径为<code>@/.snapshots/1/snapshot</code>的子卷，真正的<code>@</code>在openSUSE中是隔离开的，作为独立的根来储存需要永久保存的子卷。</p><h3 id="创建子卷的正规步骤"><a class="markdownIt-Anchor" href="#创建子卷的正规步骤"></a> 创建子卷的正规步骤</h3><p>正如上述讨论，由于目前的系统目录也是一个（临时）快照。<br />如果我们此时要创建一个子卷，不可以建立在一个一个已有的快照下，否则在进行rollback操作后就不能再删除这个子卷了。正确的操作因该是将这个子卷建立在<code>@</code>子卷下。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">sudo mount /dev/sda2 -o subvol=@ /mnt<br>sudo btrfs subvolume create /mnt/usr/important<br>sudo umount /mnt<br></code></pre></div></td></tr></table></figure><h2 id="快照"><a class="markdownIt-Anchor" href="#快照"></a> 快照</h2><p>Btrfs的快照是建立在其“写时复制”的功能基础上的。<br />创建快照可以使用如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">btrfs subvolume snapshot &lt;/path/to/source&gt; &lt;/path/to/dest&gt;<br></code></pre></div></td></tr></table></figure><blockquote><p>对于openSUSE，目标目录通常为<code>/.shapshots</code>，这一目录为默认的统一存放快照的目录。<br />另外添加参数<code>-r</code>可以创建只读快照，在只读快照上再创建一个快照可以获得只读快照的一个可写版本。</p></blockquote><p>注意快照<strong>不是递归包含</strong>的，意味着子卷里的子卷在快照中会是空目录。<br />这也是为什么openSUSE下部分目录被排除在默认的snapper备份之外：它们都被创建为了额外的子卷，由于上述非递归性，他们在对<code>/</code>创建的快照中均被忽略了。</p><h2 id="btrfs启用压缩"><a class="markdownIt-Anchor" href="#btrfs启用压缩"></a> Btrfs启用压缩<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup></h2><p>在openSUSE中是支持Btrfs的压缩功能的，通过<code>mount</code>的参数可以启用压缩：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">mount -o compress &lt;/dev/sdx&gt; &lt;/mount/point&gt;<br></code></pre></div></td></tr></table></figure><p><code>compress</code>的默认规则是：如果你创建了一个文件，Btrfs压缩后发现压缩率低，那对于之后的写入它都不再会进行压缩。如果不希望这样，可以使用<code>compress-force</code>。<br />对于已经写入的文件，均不会被压缩，<strong>压缩仅对新写入的文件有效</strong>。</p><p>压缩有三种算法可选：</p><ol><li><strong>lzo</strong>：压缩率低但是CPU资源占用少。</li><li><strong>zlib</strong>：压缩率高但是资源占用多。</li><li><strong>zstd</strong>：旧版本内核和<code>GRUB</code>引导对其缺乏支持，暂时忽略。</li></ol><p>在<code>fstab</code>中永久启用压缩，并指定压缩算法（算法以不指定）：</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">UUID=1a2b3c4d /home btrfs subvol=@/home,compress=lzo  0   0<br></code></pre></div></td></tr></table></figure><h2 id="使用snapper进行管理"><a class="markdownIt-Anchor" href="#使用snapper进行管理"></a> 使用snapper进行管理<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup></h2><p><code>snapper</code>通过一系列的配置来管理Btrfs分区，配置文件默认位于<code>/etc/snapper/configs/</code>下。<br />默认的方案只为<code>/</code>创建快照，且内容还要排除名下的子卷。</p><h3 id="创建一个新的配置"><a class="markdownIt-Anchor" href="#创建一个新的配置"></a> 创建一个新的配置</h3><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">sudo snapper -c &lt;config-name&gt; create-config &lt;/path&gt;<br></code></pre></div></td></tr></table></figure><p>这一操作会创建一个快照并从<code>/etc/snapper/config-templates/default</code>获取一套默认配置。</p><h3 id="配置快照的设置"><a class="markdownIt-Anchor" href="#配置快照的设置"></a> 配置快照的设置</h3><p>见openSUSE<a href="https://documentation.suse.com/zh-cn/sles/12-SP4/html/SLES-all/cha-snapper.html#sec-snapper-config-modify">相关文档的对应章节</a>，以获得更准确的信息。</p><p>使用<code>snapper -c home set-config &quot;&lt;KEY&gt;=&lt;value&gt;&quot;</code>来修改设置。</p><!-- footnotes --><hr class="footnotes-sep" /><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://zh.wikipedia.org/wiki/%E5%AF%AB%E5%85%A5%E6%99%82%E8%A4%87%E8%A3%BD">写入时复制 | 维基百科</a> <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p><a href="https://btrfs.wiki.kernel.org/index.php/SysadminGuide#Copy_on_Write_.28CoW.29">关于CoW的缺点 | SysadminGuide - btrfs Wiki</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p><a href="https://wiki.archlinux.org/index.php/Btrfs_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6_(CoW)">写时复制 | Btrfs (简体中文) - ArchWiki</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p><a href="https://wiki.archlinux.org/index.php/Btrfs_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#%E5%AD%90%E5%8D%B7">子卷 | Btrfs (简体中文) - ArchWiki</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p><a href="https://forums.opensuse.org/showthread.php/521277-LEAP-42-2-btrfs-root-filesystem-subvolume-structure">关于openSUSE上的Btrfs结构的讨论 | LEAP 42.2 btrfs root filesystem subvolume structure</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p><a href="https://en.opensuse.org/SDB:BTRFS#Compressed_btrfs_filesystems">在挂载时启用压缩功能 | #Compressed btrfs filesystems - SDB:BTRFS - openSUSE Wiki</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p><a href="https://documentation.suse.com/zh-cn/sles/12-SP4/html/SLES-all/cha-snapper.html#sec-snapper-config">通过 Snapper 进行系统恢复和快照管理 | 管理指南 | SUSE Linux Enterprise Server 12 SP4</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    
    <categories>
      
      <category>Linux - 系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux系统恢复记录</title>
    <link href="/2020/02/22/Linux%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/02/22/Linux%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>这篇文章的起因是在Windows下的一次分区操作，结果导致了一段悲伤的故事T^T。<br />不过这一次的系统崩溃还是有不少收获的：</p><ol><li>捡回了我的操作系统。</li><li>和Linux双系统时，绝对不要在Windows下进行分区操作。</li><li>关于Linux分区丢失之后的找回方法（重要）。</li><li>启动问题解决途径。</li></ol><p>需要注意的是，这篇文章并非是对这一问题的专业解读，只是一个问题解决的思路的整理（<strong>思路&gt;问题解决&gt;放置问题</strong>）。</p><p>最终的建议可能是，不要在有双系统的时候，在Windows下进行分区操作，ubuntu的Live CD是个不错的选择，里面一直自带gparted。</p><span id="more"></span><p>放张目前的桌面 😄<br />估计可以写一篇美化指南了？？Linux的美化是费时费力的，但收获是成正比的。</p><img src="/2020/02/22/Linux%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95/current-desktop.png" class="" title="current-desktop">\<h2 id="windows分区会导致的问题"><a class="markdownIt-Anchor" href="#windows分区会导致的问题"></a> Windows分区会导致的问题</h2><p>首先，导致问题的根源在于使用Windows下的软件进行了分区（具体是使用了傲梅分区助手），正常情况在Windows环境下使用这个软件是不会有任何问题的，但是关于Linux系统这一面就不是同一回事了。</p><p>由于这一（但不仅限于）分区软件并不识别所有的分区类型，对于Linux下典型的Ext分区是直接不显示的。</p><blockquote><p>直接显示了未分配，视为了空白空间</p></blockquote><p>要导致Linux下分区消失，根据以往经历，笔者猜测出需要满足这两个条件：</p><ol><li>首先就是<strong>分区不显示</strong>，不能识别这一分区。</li></ol><blockquote><p>理由是隔壁的DiskGenius在我装完Linux后装Windows时也进行了分区操作，但是并没有出现问题，此时DiskGenius是识别了的，只是显示未知分类。</p></blockquote><ol start="2"><li><strong>对于分区表进行了改动</strong>，出现了分区的创建、格式化成另一种格式，不包含移动分区。</li></ol><blockquote><p>我这一次问题出现的原因就是把一个Fat32格式的分区格式化成了exFat，但同种格式的格式化预估不会有问题。至于移动分区，在之前也用傲梅分区助手移动过两个ESP分区，但是均没有出现问题。</p></blockquote><h3 id="分区编号的重置"><a class="markdownIt-Anchor" href="#分区编号的重置"></a> 分区编号的重置</h3><p>在使用Windows下的分区软件进行分区编辑之后，在Linux这一边都会遇到同样的一个问题：分区编号变了！</p><p>想必有些许了解就会知道，在linux下分区是标成sda1，sda2，……这样的格式的，但是Windows下倒没有遇到这一概念。问题在于Windows下分区后，这些编号会重置，序号会对因它是磁盘内从头开始的第几个分区，可能直接导致Linux下依赖于此的挂载出现问题。所以尽量使用UUID进行区分吧。</p><h3 id="问题的根源猜测"><a class="markdownIt-Anchor" href="#问题的根源猜测"></a> 问题的根源（猜测）</h3><p>基于个人已有的信息，导致分区消失的根本原因因该是Windows下的分区操作导致了分区表被重写了，而那些未被识别的分区，由于软件根本不识别他们，因而直接在重建的时候跳过了这些分区。这也能解释为什么移动没有问题：修改起止的扇区号即可。<br />总之这样导致的分区丢失可以概括成：<strong>分区没事，分区表炸了</strong>。这一点还是十分肯定的。</p><hr /><h2 id="分区找回"><a class="markdownIt-Anchor" href="#分区找回"></a> 分区找回</h2><p>既然问题的原因在于分区表被改写后，着一分区没有被纳入到分区表，那么可以送一口气的是：数据没事。毕竟数据没有被覆盖写入，就不会有问题。那问题就在于怎么把分区给补回分区表了，这一操作简单便捷，但是倒没找到什么资料，百度也保持着它的传统……</p><h3 id="问题确认"><a class="markdownIt-Anchor" href="#问题确认"></a> 问题确认</h3><p>分区丢失的症状很明显：重启后引导不了，直接进入了Grub，Windows继续活得蛮滋润。<br />在Grub命令行下使用基本的命令可以查看到分区，以此确认分区是否丢失。</p><h3 id="分区修复"><a class="markdownIt-Anchor" href="#分区修复"></a> 分区修复</h3><h4 id="step-1-准备一ubuntu镜像"><a class="markdownIt-Anchor" href="#step-1-准备一ubuntu镜像"></a> Step 1. 准备一Ubuntu镜像</h4><p>要修复分区，首先需要准备一个ubuntu镜像。制作过程很简单，基于UEFI的便捷与强大，只需要创建一个Fat32格式的分区然后把镜像内文件全复制进去，在BIOS的启动菜单里就因该能看到这一启动项了，这一步可以参照网上的装Ubuntu的教程。启动后<strong>选择试用（Try xxx!)</strong>，进入下一步。</p><h4 id="step-2-使用fdisk创建分区"><a class="markdownIt-Anchor" href="#step-2-使用fdisk创建分区"></a> Step 2. 使用fdisk创建分区</h4><p>工具使用fdisk，在Ubuntu下是自带的。其实并不限于Ubuntu，能用fdisk即可完成下面的修复。<br />下面截图来自于模拟，在这一次的分区丢失中，我的Swap分区也被删除了，就用它的恢复来做一个例子。</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">sudo fdisk /dev/nvme0n1<br></code></pre></div></td></tr></table></figure><img src="/2020/02/22/Linux%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95/fdisk.png" class="" title="fdisk"><p>之后使用fdisk在原本分区所在的位置重新创建一个分区即可：</p><img src="/2020/02/22/Linux%E7%B3%BB%E7%BB%9F%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95/create_new_disk.png" class="" title="create_new_disk">]]></content>
    
    
    <categories>
      
      <category>Linux - 恢复</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tf.data数据加载</title>
    <link href="/2020/02/21/tf-data%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/"/>
    <url>/2020/02/21/tf-data%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/</url>
    
    <content type="html"><![CDATA[<p><code>tf.data</code>用于构建Tensorflow的数据加载。</p><p>在<code>tf.data</code>中引入了<code>tf.data.Dataset</code>这样一个抽象来表示一系列的element，每一个元素都由一定的component组成。（如一个图像训练的样本可以看作一个element，其中包含了图像和标签两个component）</p><span id="more"></span><h2 id="获取数据输入"><a class="markdownIt-Anchor" href="#获取数据输入"></a> 获取数据输入</h2><h3 id="由numpy数组创建"><a class="markdownIt-Anchor" href="#由numpy数组创建"></a> 由NumPy数组创建</h3><p>对于在内存中的数据，使用<code>Dataset.from_tensor_slice</code>是最方便的：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">train, test = tf.keras.datasets.fashion_mnist.load_data()<br>dataset = tf.data.Dataset.from_tensor_slices((images, labels))<br></code></pre></div></td></tr></table></figure><blockquote><p>☆ 上面的创建方式仅适用于小数据集，因为浪费内存。</p></blockquote><h3 id="由python-generator创建"><a class="markdownIt-Anchor" href="#由python-generator创建"></a> 由Python generator创建</h3><p><code>Dataset.from_generator</code>将一个Python generator转换为<code>tf.data.Dataset</code>，它以一个callable作为输入（而非一个iterator）。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">ds_counter = tf.data.Dataset.from_generator(count,  <span class="hljs-comment"># python generator</span><br>                                            output_types=tf.int32,<br>                                            args=[<span class="hljs-number">25</span>],  <span class="hljs-comment"># args for generator</span><br>                                            output_shapes = (),<br>                                            )<br></code></pre></div></td></tr></table></figure><p>在参数列表中：<br /><code>args</code>用来提供Python generator初始化所需要的参数。<br /><code>output_type</code>必须要指定以确定数据类型。<br /><code>output_shape</code>是可选的，但是因为Tensorflow中的部分操作不支持未知的shape因而最好指定。如果shape是可变的或未知，可以定义为<code>None</code>，对于scalar其形状为<code>()</code>。</p><blockquote><p>☆ 使用比较方便，但是需要注意可能会有兼容性、可移植性方面的问题。</p></blockquote><h3 id="由tfrecord创建"><a class="markdownIt-Anchor" href="#由tfrecord创建"></a> 由TFRecord创建</h3><p>使用<code>tf.data.TFRecordDataset</code>来实现从一个或多个TFRecord文件导入数据，只需要提供<code>filenames</code>参数即可，接受单一字符串、字符串列表或者字符型的<code>tf.Tensor</code>。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])<br></code></pre></div></td></tr></table></figure><p>这样读出来的只是<strong>二进制数据</strong>，通常使用<code>tf.train.Example</code>来序列化存储，对于这样的数据需要进行解码：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">raw_example = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(dataset))<br>parsed = tf.train.Example.FromString(raw_example.numpy())<br><br>parsed.features.feature[<span class="hljs-string">&#x27;image/text&#x27;</span>]<br></code></pre></div></td></tr></table></figure><h3 id="由text数据创建"><a class="markdownIt-Anchor" href="#由text数据创建"></a> 由text数据创建</h3><p>使用<code>tf.data.TextLineDataset</code>，只需要提供<code>.txt</code>格式的文件路径即可：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">dataset = tf.data.TextLineDataset(file_paths)<br></code></pre></div></td></tr></table></figure><p>默认的<code>TextLineDataset</code>是逐个文件地给出其中的每一行，使用<code>Dataset.interleave</code>可以在各个文件之间依次切换着输出每一行。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">files_ds = tf.data.Dataset.from_tensor_slices(file_paths)<br>lines_ds = files_ds.interleave(tf.data.TextLineDataset, cycle_length=<span class="hljs-number">3</span>)<br></code></pre></div></td></tr></table></figure><h3 id="由csv数据创建"><a class="markdownIt-Anchor" href="#由csv数据创建"></a> 由CSV数据创建</h3><p>对于CSV格式的数据，在加载到内存之后当然也可以使用<code>Dataset.from_tensor_slice</code>来创建<code>Dataset</code>，不过我们更希望能直接从硬盘中读取。<br /><code>experimental.make_csv_dataset</code>可以直接读取CSV格式的文件：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">titanic_batches = tf.data.experimental.make_csv_dataset(<br>    titanic_file, batch_size=<span class="hljs-number">4</span>,<br>    label_name=<span class="hljs-string">&quot;survived&quot;</span>)  <span class="hljs-comment"># survived这一列被额外划分为标签列</span><br><br><span class="hljs-keyword">for</span> feature_batch, label_batch <span class="hljs-keyword">in</span> titanic_batches.take(<span class="hljs-number">1</span>):  <span class="hljs-comment"># 返回时，数据和标签会分开返回</span><br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#x27;survived&#x27;: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(label_batch))<br>  ...<br></code></pre></div></td></tr></table></figure><p>另外，<code>select_columns</code>参数可以只把其中需要的几列挑选出来：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">titanic_batches = tf.data.experimental.make_csv_dataset(..., select_columns=[<span class="hljs-string">&#x27;class&#x27;</span>, <span class="hljs-string">&#x27;fare&#x27;</span>, <span class="hljs-string">&#x27;survived&#x27;</span>])<br></code></pre></div></td></tr></table></figure><p>💊<strong>直接通过这一个函数创建的数据集，label部分是按照标签分开的，需要使用一下方式进行合并！</strong></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">pack_features_vector</span>(<span class="hljs-params">features, labels</span>):<br>  <span class="hljs-string">&quot;&quot;&quot;将特征打包到一个数组中&quot;&quot;&quot;</span><br>  features = tf.stack(<span class="hljs-built_in">list</span>(features.values()), axis=<span class="hljs-number">1</span>)<br>  <span class="hljs-keyword">return</span> features, labels<br></code></pre></div></td></tr></table></figure><p>除了这一个函数，还有一个更低级的<a href="https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset"><code>experimental.CsvDataset</code></a>，它不支持每一列的自动类型推导，但这也意味着可以手动控制每一列的数据类型，并且第二个参数还可以同时为空缺的数据指定默认值。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 依次指定每一列的类型</span><br>titanic_types  = [tf.int32, tf.string, tf.float32, tf.int32, tf.int32, tf.float32, tf.string, tf.string, tf.string, tf.string]<br>dataset = tf.data.experimental.CsvDataset(titanic_file, titanic_types , header=<span class="hljs-literal">True</span>)<br></code></pre></div></td></tr></table></figure><blockquote><p>☆ 从函数名可以看出这一系列都是实验性函数，之后版本的API中可能出现更改。</p></blockquote><h3 id="由一系列文件创建"><a class="markdownIt-Anchor" href="#由一系列文件创建"></a> 由一系列文件创建</h3><p>有时候数据集会以分散在目录里的一系列文件的形式给出，对于这样的数据可以以文件路径作为信息构建数据集，使用<code>Dataset.list_files()</code>函数来构建：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">list_ds = tf.data.Dataset.list_files(<span class="hljs-built_in">str</span>(flowers_root/<span class="hljs-string">&#x27;*/*&#x27;</span>))<br></code></pre></div></td></tr></table></figure><p>其中每一个element的形式是文件路径：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-string">b&#x27;/home/kbuilder/.keras/datasets/flower_photos/roses/15566697073_9a214b700e_n.jpg&#x27;</span><br></code></pre></div></td></tr></table></figure><hr /><h2 id="数据处理"><a class="markdownIt-Anchor" href="#数据处理"></a> 数据处理</h2><h3 id="datasetmap"><a class="markdownIt-Anchor" href="#datasetmap"></a> Dataset.map</h3><p>对于数据处理，一个很重要的变换函数是<code>Dataset.map</code>，它可以将一个指定的函数<code>f</code>应用到数据集中的每一个element上，以实现数据的批量处理。</p><p>在指定的函数<code>f</code>中，可以使用Tensorflow的API，也支持使用其他的Python API来处理数据。<br />对于一些使用<code>tf.Train.Example</code>原型来存储的数据，就理所当然的可以应用<code>Dataset.map</code>来对原始数据进行解码。</p><h4 id="通过datasetmap实现图像解码"><a class="markdownIt-Anchor" href="#通过datasetmap实现图像解码"></a> 通过Dataset.map实现图像解码</h4><p>很显然图像的解码可以通过和<code>Dataset.map</code>的配合来实现。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 1. 载入原始数据集</span><br>list_ds = tf.data.Dataset.list_files(<span class="hljs-built_in">str</span>(flowers_root/<span class="hljs-string">&#x27;*/*&#x27;</span>))<br><br><span class="hljs-comment"># 2. 定义实现图片的解码的函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_image</span>(<span class="hljs-params">filename</span>):<br>  parts = tf.strings.split(filename, <span class="hljs-string">&#x27;/&#x27;</span>)<br>  label = parts[-<span class="hljs-number">2</span>]<br><br>  image = tf.io.read_file(filename) <span class="hljs-comment"># 读入图片（文本形式）</span><br>  image = tf.image.decode_jpeg(image) <span class="hljs-comment"># 解码成正式的图片数据</span><br>  image = tf.image.convert_image_dtype(image, tf.float32)<br>  image = tf.image.resize(image, [<span class="hljs-number">128</span>, <span class="hljs-number">128</span>])  <span class="hljs-comment"># 也提供了resize操作</span><br>  <span class="hljs-keyword">return</span> image, label<br><br><span class="hljs-comment"># 3. 通过map方法来应用到每一个element上</span><br>images_ds = list_ds.<span class="hljs-built_in">map</span>(parse_image)<br></code></pre></div></td></tr></table></figure><h3 id="样本过滤"><a class="markdownIt-Anchor" href="#样本过滤"></a> 样本过滤</h3><p>使用<a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#skip"><code>Dataset.skip()</code></a>变换可以跳过开头的几个样本，<a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#filter"><code>Dataset.filter()</code></a>可以使用特定的条件对于数据集中的element进行筛选，只需要提供一个判断用的函数。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">survived</span>(<span class="hljs-params">line</span>):     <span class="hljs-comment"># 函数定义判断条件，符合条件的时候返回true，保留对应元素</span><br>  <span class="hljs-keyword">return</span> tf.not_equal(tf.strings.substr(line, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>), <span class="hljs-string">&quot;0&quot;</span>)<br><br>survivors = titanic_lines.skip(<span class="hljs-number">1</span>).<span class="hljs-built_in">filter</span>(survived)<br></code></pre></div></td></tr></table></figure><h3 id="时序数据"><a class="markdownIt-Anchor" href="#时序数据"></a> 时序数据</h3><p>对于和时序相关的数据，原始数据是“时间”上连续的，为了构建数据集，我们往往需要以此创建连续的时间切片。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">range_ds = tf.data.Dataset.<span class="hljs-built_in">range</span>(<span class="hljs-number">100000</span>)  <span class="hljs-comment"># 以range为例</span><br></code></pre></div></td></tr></table></figure><h4 id="通过batch"><a class="markdownIt-Anchor" href="#通过batch"></a> 通过batch</h4><p>基本思路为：</p><ol><li>先转化为一系列batch，这样每一个element就是一个batch的数据。</li><li>应用<code>Dataset.map</code>来处理每一个batch，分割出输入和输出。</li></ol><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># step 1 变为batch</span><br>batches = range_ds.batch(<span class="hljs-number">10</span>, drop_remainder=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># step 2 通过map来分割，创建出训练数据和标签</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dense_1_step</span>(<span class="hljs-params">batch</span>):<br>  <span class="hljs-comment"># Shift features and labels one step relative to each other.</span><br>  <span class="hljs-keyword">return</span> batch[:-<span class="hljs-number">1</span>], batch[<span class="hljs-number">1</span>:]<br><br>predict_dense_1_step = batches.<span class="hljs-built_in">map</span>(dense_1_step)<br></code></pre></div></td></tr></table></figure><h4 id="通过window"><a class="markdownIt-Anchor" href="#通过window"></a> 通过window</h4><p>使用<code>Dataset.window</code>可以更好地控制这一个过程，但注意这一函数返回的Dataset中element依旧是Dataset。可以利用<code>Dataset.flat_map</code>方法，它要求作为参数的<code>map_func</code>是一个将element转化为Dataset的函数，然后它会将返回的Dataset展开。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_window_dataset</span>(<span class="hljs-params">ds, window_size=<span class="hljs-number">5</span>, shift=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span></span>):<br>  windows = ds.window(window_size, shift=shift, stride=stride)<br>  <span class="hljs-comment"># shift代表窗口每次滑动的量，而stride代表元素之间的间隔</span><br><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">sub_to_batch</span>(<span class="hljs-params">sub</span>):  <span class="hljs-comment"># 转化为batch，这样之后的处理手法就和上面通过batch的方法一致了</span><br>    <span class="hljs-keyword">return</span> sub.batch(window_size, drop_remainder=<span class="hljs-literal">True</span>)<br>  <br>  windows = windows.flat_map(sub_to_batch)<br>  <span class="hljs-keyword">return</span> windows<br><br>ds = make_window_dataset(range_ds, window_size=<span class="hljs-number">10</span>, shift = <span class="hljs-number">5</span>, stride=<span class="hljs-number">3</span>)<br><br><span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> ds.take(<span class="hljs-number">10</span>):<br>  <span class="hljs-built_in">print</span>(example.numpy())<br>  <span class="hljs-comment"># [ 0  3  6  9 12 15 18 21 24 27]</span><br>  <span class="hljs-comment"># [ 5  8 11 14 17 20 23 26 29 32]</span><br>  <span class="hljs-comment"># ...</span><br>  <span class="hljs-comment"># [45 48 51 54 57 60 63 66 69 72]</span><br></code></pre></div></td></tr></table></figure><p>这样就相当于在整一条的数据上使用“滑动窗口”一样的方法，以特定的shift值过了一遍。之后再利用上面的在batch中创建出训练集和标签的方法，即可完成数据集的创建。</p><hr /><h2 id="数据输出"><a class="markdownIt-Anchor" href="#数据输出"></a> 数据输出</h2><h3 id="分批量输出"><a class="markdownIt-Anchor" href="#分批量输出"></a> 分批量输出</h3><h4 id="定长数据batch"><a class="markdownIt-Anchor" href="#定长数据batch"></a> 定长数据：batch</h4><p>使用<code>Dataset.batch()</code>可以方便地产生批量数据，约束条件是其中每一个元素都要拥有相同的形状。<br />对于输出的批量，在默认的函数设置下是未知的，因为最后一个batch可能是不全的，Tensorflow无法判断所以将其形状设为None。可以使用<code>drop_remainder</code>参数来丢弃最后一个不完全的batch，这样其形状就会固定了。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">batched_dataset = dataset.batch(<span class="hljs-number">7</span>, drop_remainder=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># &lt;BatchDataset shapes: ((7,), (7,)), types: (tf.int64, tf.int64)&gt;</span><br><span class="hljs-comment"># 如果drop_remainder设为False则为</span><br><span class="hljs-comment"># &lt;BatchDataset shapes: ((None,), (None,)), types: (tf.int64, tf.int64)&gt;</span><br><span class="hljs-comment"># 形状不能确定</span><br></code></pre></div></td></tr></table></figure><h4 id="不定长数据padded_batch"><a class="markdownIt-Anchor" href="#不定长数据padded_batch"></a> 不定长数据：padded_batch</h4><p>对于不定长的数据，在分批量调用的时候注意使用<code>Dataset.padded_batch</code>而非一般性的<code>Dataset.batch</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">ds_series_batch = ds_series.shuffle(<span class="hljs-number">20</span>).padded_batch(<span class="hljs-number">10</span>,((),(<span class="hljs-literal">None</span>,))<br><br>ids, sequence_batch = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(ds_series_batch))<br><span class="hljs-built_in">print</span>(ids.numpy())<br><span class="hljs-built_in">print</span>()<br><span class="hljs-built_in">print</span>(sequence_batch.numpy())<br></code></pre></div></td></tr></table></figure><blockquote><p>☆ padded_batch需要指定形状，在Tensorflow Guide的文章中写错了，没有指定形状。同时形状的描述也很特别，值得考量。<br />填充的值可以指定。<br />详见API：<a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch"><code>Dataset.padded_batch</code></a>。</p></blockquote><p>输出形式如下：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">[ <span class="hljs-number">2</span> <span class="hljs-number">16</span> <span class="hljs-number">20</span> <span class="hljs-number">10</span>  <span class="hljs-number">6</span> <span class="hljs-number">14</span> <span class="hljs-number">19</span>  <span class="hljs-number">9</span> <span class="hljs-number">24</span> <span class="hljs-number">27</span>]<br><br>[[ <span class="hljs-number">0.4466</span>  <span class="hljs-number">0.6624</span>  <span class="hljs-number">1.4652</span>  <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>    ]<br> [ <span class="hljs-number">0.2223</span> -<span class="hljs-number">0.6065</span>  <span class="hljs-number">0.5422</span>  <span class="hljs-number">0.4195</span>  <span class="hljs-number">0.5124</span> -<span class="hljs-number">0.5322</span>  <span class="hljs-number">0.0428</span>  <span class="hljs-number">0.3617</span>  <span class="hljs-number">1.5245</span>]<br> ...<br> [-<span class="hljs-number">0.3334</span> -<span class="hljs-number">1.0381</span>  <span class="hljs-number">1.1201</span> -<span class="hljs-number">0.4033</span> -<span class="hljs-number">0.6819</span>  <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>      <span class="hljs-number">0.</span>    ]]<br></code></pre></div></td></tr></table></figure><h3 id="多epoch重复输出"><a class="markdownIt-Anchor" href="#多epoch重复输出"></a> 多epoch重复输出</h3><p>使用<code>Dataset.repeat()</code>变换可以实现重复枚举数据：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">titanic_batches = titanic_lines.repeat(<span class="hljs-number">3</span>).batch(<span class="hljs-number">128</span>)<br></code></pre></div></td></tr></table></figure><blockquote><p>无参数的<code>Dataset.repeat()</code>会无限地重复枚举。<br />注意<code>repeat</code>和<code>batch</code>的调用顺序会影响输出数据的长度变化（主要因为最后一个batch会不全）:</p></blockquote><table><thead><tr><th style="text-align:center">先repeat</th><th style="text-align:center">先batch</th></tr></thead><tbody><tr><td style="text-align:center"><img src="/2020/02/21/tf-data%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/2020-06-30T161153.png" class="" title="2020-06-30T161153"></td><td style="text-align:center"><img src="/2020/02/21/tf-data%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/2020-06-30T161231.png" class="" title="2020-06-30T161231"></td></tr></tbody></table><h3 id="随机化"><a class="markdownIt-Anchor" href="#随机化"></a> 随机化</h3><p><code>Dataset.shuffle()</code>通过维护指定大小的buffer并<strong>从中</strong>随机选取来实现一定程度的随机输出。</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">dataset = dataset.shuffle(buffer_size=<span class="hljs-number">100</span>)<br></code></pre></div></td></tr></table></figure><blockquote><p>☆ 对于这样的随机方案，随机的完全性取决于buffer的大小，大的buffer虽然随机性更好但是占用<strong>大量内存</strong>。<br />对于随机，先调用<code>repeat</code>或是<code>shuffle</code>也会存在差异：</p><img src="/2020/02/21/tf-data%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD/2020-06-30T161257.png" class="" title="2020-06-30T161257"></blockquote><hr /><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ol><li><a href="https://www.tensorflow.org/guide/data#consuming_csv_data">tf.data: Build TensorFlow input pipelines | TensorFlow Core</a></li><li><a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">tf.data.Dataset | TensorFlow Core</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习 - 数据处理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
